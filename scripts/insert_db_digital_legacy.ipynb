{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "769e2868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from uuid import uuid4\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import json\n",
    "from typing import List\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2799c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'digital_legacy': {'vector_count': 68},\n",
      "                'funeral_facilities': {'vector_count': 2518},\n",
      "                'guide': {'vector_count': 4},\n",
      "                'ordinance': {'vector_count': 234}},\n",
      " 'total_vector_count': 2824,\n",
      " 'vector_type': 'dense'} \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "INDEX_NAME = \"funeral-services\"\n",
    "pc = Pinecone()\n",
    "index = pc.Index(INDEX_NAME)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "print(index.describe_index_stats(), '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f1e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index.delete(delete_all=True, namespace=\"funeral_facilities\")\n",
    "# print(index.describe_index_stats(), '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d46ae0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_FILES = [\n",
    "    \"identity_verification_service_chunked.json\",\n",
    "    \"naver_data1_chunked.json\",\n",
    "    \"naver_data2_chunked.json\",\n",
    "    \"online_shoppingmal_chunked.json\",\n",
    "    \"google_data1_chunked.json\",\n",
    "    \"google_data2_chunked.json\",\n",
    "    \"kakaotalk_data1_chunked.json\",\n",
    "    \"kakaotalk_data2_chunked.json\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee0d523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chunks(path: str):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        chunks = json.load(f)\n",
    "    print(f\"[INFO] ì´ {len(chunks)}ê°œì˜ ì²­í¬ ë¡œë“œ ì™„ë£Œ.\")\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bacd69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_chunks_to_pinecone(chunks, batch_size: int = 100):\n",
    "    total = len(chunks)\n",
    "    vectorstore = PineconeVectorStore(\n",
    "            index_name=INDEX_NAME,\n",
    "            embedding=embeddings,\n",
    "            namespace='digital_legacy'\n",
    "    )\n",
    "    for start in range(0, total, batch_size):\n",
    "        end = min(start + batch_size, total)\n",
    "        batch = chunks[start:end]\n",
    "\n",
    "        # 1) í…ìŠ¤íŠ¸ / ID ì¶”ì¶œ\n",
    "        texts = [c[\"text\"] for c in batch]   # JSONì˜ text í•„ë“œ\n",
    "        ids = [c[\"id\"] for c in batch]       # JSONì˜ id í•„ë“œ\n",
    "\n",
    "        # 2) ë©”íƒ€ë°ì´í„° êµ¬ì„±\n",
    "        metadatas = []\n",
    "        for c in batch:\n",
    "            base_meta = c.get(\"metadata\", {}) or {}\n",
    "\n",
    "            # ê¸°ë³¸ ë©”íƒ€ë°ì´í„° + ì›ë³¸ metadata í•©ì¹˜ê¸°\n",
    "            meta = {\n",
    "                \"chunk_id\": c[\"id\"],\n",
    "                \"text\": c[\"text\"],\n",
    "            }\n",
    "            meta.update(base_meta)\n",
    "\n",
    "            # ğŸ”¥ None ì œê±°\n",
    "            clean_meta = {k: v for k, v in meta.items() if v is not None}\n",
    "\n",
    "            metadatas.append(clean_meta)\n",
    "\n",
    "        vectorstore.add_texts(\n",
    "            texts=texts,\n",
    "            metadatas=metadatas,\n",
    "            ids=ids\n",
    "        )    \n",
    "        \n",
    "        print(f\"[INFO] ì—…ì„œíŠ¸ ì§„í–‰: {end}/{total} ê°œ ì™„ë£Œ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0bd75ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_chunk_file(json_path: str, source_name: str | None = None):\n",
    "    \"\"\"\n",
    "    json_pathì— ìˆëŠ” ì²­í‚¹ JSON íŒŒì¼ì„ ë¡œë“œí•´ì„œ\n",
    "    Pinecone ì¸ë±ìŠ¤ë¡œ ì—…ë¡œë“œí•˜ëŠ” í¸ì˜ í•¨ìˆ˜.\n",
    "    \"\"\"\n",
    "    print(f\"[INFO] ì—…ë¡œë“œ ì‹œì‘: {json_path}\")\n",
    "\n",
    "    if not os.path.exists(json_path):\n",
    "        print(f\"[WARN] íŒŒì¼ ì—†ìŒ, ê±´ë„ˆëœ€: {json_path}\")\n",
    "        return\n",
    "\n",
    "    chunks = load_chunks(json_path)\n",
    "\n",
    "    # í•„ìš”í•˜ë‹¤ë©´ ì—¬ê¸°ì„œ source_nameì„ ë©”íƒ€ë°ì´í„°ì— ì¶”ê°€í•˜ëŠ” ë¡œì§ì„\n",
    "    # upsert_chunks_to_pinecone ìª½ìœ¼ë¡œ ë„˜ê²¨ë„ ë¨.\n",
    "    upsert_chunks_to_pinecone(chunks, batch_size=100)\n",
    "\n",
    "    print(f\"[INFO] ì—…ë¡œë“œ ì™„ë£Œ: {json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53d48de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] ì—…ë¡œë“œ ì‹œì‘: ../data/processed\\identity_verification_service_chunked.json\n",
      "[INFO] ì´ 5ê°œì˜ ì²­í¬ ë¡œë“œ ì™„ë£Œ.\n",
      "[INFO] ì—…ì„œíŠ¸ ì§„í–‰: 5/5 ê°œ ì™„ë£Œ.\n",
      "[INFO] ì—…ë¡œë“œ ì™„ë£Œ: ../data/processed\\identity_verification_service_chunked.json\n",
      "[INFO] ì—…ë¡œë“œ ì‹œì‘: ../data/processed\\naver_data1_chunked.json\n",
      "[INFO] ì´ 6ê°œì˜ ì²­í¬ ë¡œë“œ ì™„ë£Œ.\n",
      "[INFO] ì—…ì„œíŠ¸ ì§„í–‰: 6/6 ê°œ ì™„ë£Œ.\n",
      "[INFO] ì—…ë¡œë“œ ì™„ë£Œ: ../data/processed\\naver_data1_chunked.json\n",
      "[INFO] ì—…ë¡œë“œ ì‹œì‘: ../data/processed\\naver_data2_chunked.json\n",
      "[INFO] ì´ 11ê°œì˜ ì²­í¬ ë¡œë“œ ì™„ë£Œ.\n",
      "[INFO] ì—…ì„œíŠ¸ ì§„í–‰: 11/11 ê°œ ì™„ë£Œ.\n",
      "[INFO] ì—…ë¡œë“œ ì™„ë£Œ: ../data/processed\\naver_data2_chunked.json\n",
      "[INFO] ì—…ë¡œë“œ ì‹œì‘: ../data/processed\\online_shoppingmal_chunked.json\n",
      "[INFO] ì´ 12ê°œì˜ ì²­í¬ ë¡œë“œ ì™„ë£Œ.\n",
      "[INFO] ì—…ì„œíŠ¸ ì§„í–‰: 12/12 ê°œ ì™„ë£Œ.\n",
      "[INFO] ì—…ë¡œë“œ ì™„ë£Œ: ../data/processed\\online_shoppingmal_chunked.json\n",
      "[INFO] ì—…ë¡œë“œ ì‹œì‘: ../data/processed\\google_data1_chunked.json\n",
      "[INFO] ì´ 7ê°œì˜ ì²­í¬ ë¡œë“œ ì™„ë£Œ.\n",
      "[INFO] ì—…ì„œíŠ¸ ì§„í–‰: 7/7 ê°œ ì™„ë£Œ.\n",
      "[INFO] ì—…ë¡œë“œ ì™„ë£Œ: ../data/processed\\google_data1_chunked.json\n",
      "[INFO] ì—…ë¡œë“œ ì‹œì‘: ../data/processed\\google_data2_chunked.json\n",
      "[INFO] ì´ 10ê°œì˜ ì²­í¬ ë¡œë“œ ì™„ë£Œ.\n",
      "[INFO] ì—…ì„œíŠ¸ ì§„í–‰: 10/10 ê°œ ì™„ë£Œ.\n",
      "[INFO] ì—…ë¡œë“œ ì™„ë£Œ: ../data/processed\\google_data2_chunked.json\n",
      "[INFO] ì—…ë¡œë“œ ì‹œì‘: ../data/processed\\kakaotalk_data1_chunked.json\n",
      "[INFO] ì´ 6ê°œì˜ ì²­í¬ ë¡œë“œ ì™„ë£Œ.\n",
      "[INFO] ì—…ì„œíŠ¸ ì§„í–‰: 6/6 ê°œ ì™„ë£Œ.\n",
      "[INFO] ì—…ë¡œë“œ ì™„ë£Œ: ../data/processed\\kakaotalk_data1_chunked.json\n",
      "[INFO] ì—…ë¡œë“œ ì‹œì‘: ../data/processed\\kakaotalk_data2_chunked.json\n",
      "[INFO] ì´ 11ê°œì˜ ì²­í¬ ë¡œë“œ ì™„ë£Œ.\n",
      "[INFO] ì—…ì„œíŠ¸ ì§„í–‰: 11/11 ê°œ ì™„ë£Œ.\n",
      "[INFO] ì—…ë¡œë“œ ì™„ë£Œ: ../data/processed\\kakaotalk_data2_chunked.json\n",
      "[INFO] ì¸ë±ìŠ¤ í†µê³„:\n",
      "{'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'digital_legacy': {'vector_count': 68},\n",
      "                'funeral_facilities': {'vector_count': 2518},\n",
      "                'guide': {'vector_count': 4},\n",
      "                'ordinance': {'vector_count': 234}},\n",
      " 'total_vector_count': 2824,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = '../data/processed'\n",
    "\n",
    "for filename in CHUNK_FILES:\n",
    "    json_path = os.path.join(BASE_DIR, filename)\n",
    "    upload_chunk_file(json_path)\n",
    "\n",
    "# ë£¨í”„ ëë‚œ ë’¤, ì¸ë±ìŠ¤ í†µê³„ í™•ì¸\n",
    "stats = index.describe_index_stats()\n",
    "print(\"[INFO] ì¸ë±ìŠ¤ í†µê³„:\")\n",
    "print(stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "home_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
